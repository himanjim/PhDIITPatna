# -*- coding: utf-8 -*-
"""FaceNetvs InsightViT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SHecXCHpXeowidfrxwwjLvHMcwLwW5z2
"""

!pip install deepface insightface opencv-python-headless scikit-learn seaborn matplotlib onnxruntime

from google.colab import drive
drive.mount('/content/drive')

import os
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.metrics.pairwise import cosine_similarity
from deepface import DeepFace
import insightface
import time

# Set your dataset path here
base_dir = "/content/drive/MyDrive/PhD/Data/archive/Image_Train"

# Step 1: Load image paths grouped by identity
def load_grouped_images(base_dir):
    grouped = {}
    for person in sorted(os.listdir(base_dir)):
        person_path = os.path.join(base_dir, person)
        if os.path.isdir(person_path):
            images = [os.path.join(person_path, f)
                      for f in os.listdir(person_path)
                      if f.lower().endswith(('jpg', 'jpeg', 'png'))]
            if images:
                grouped[person] = images
    return grouped

grouped_images = load_grouped_images(base_dir)
print(f"âœ… Loaded {len(grouped_images)} identities.")

# Step 2: Generate positive and negative pairs
def generate_pairs(grouped_images):
    pairs = []
    persons = list(grouped_images.keys())

    # Positive pairs
    for person, imgs in grouped_images.items():
        for i in range(len(imgs)):
            for j in range(i + 1, len(imgs)):
                pairs.append((imgs[i], imgs[j], 1))

    # Negative pairs: all combinations between different identities
    for i in range(len(persons)):
        for j in range(i + 1, len(persons)):
            for img1 in grouped_images[persons[i]]:
                for img2 in grouped_images[persons[j]]:
                    pairs.append((img1, img2, 0))

    return pairs

pairs = generate_pairs(grouped_images)
print(f"âœ… Total image pairs: {len(pairs)}")

# Step 3: Compute embeddings only once

# Initialize DeepFace FaceNet512
def compute_facenet_embeddings(image_paths, detector_backend='retinaface'):
    embeddings = {}
    for img_path in tqdm(image_paths, desc="ðŸ§  FaceNet512 embeddings"):
        try:
            rep = DeepFace.represent(
                img_path=img_path,
                model_name="Facenet512",
                detector_backend=detector_backend,
                enforce_detection=True
            )
            embeddings[img_path] = rep[0]["embedding"]
        except Exception as e:
            print(f"[âš ï¸ FaceNet] Failed {img_path}: {e}")
    return embeddings

# Initialize InsightFace ViT
insight_model = insightface.app.FaceAnalysis(name='buffalo_l')
insight_model.prepare(ctx_id=0)

def compute_insight_embeddings(image_paths):
    embeddings = {}
    for img_path in tqdm(image_paths, desc="ðŸ§  InsightFace embeddings"):
        try:
            img = cv2.imread(img_path)
            faces = insight_model.get(img)
            if faces:
                embeddings[img_path] = faces[0].embedding
        except Exception as e:
            print(f"[âš ï¸ InsightFace] Failed {img_path}: {e}")
    return embeddings

# Get all unique image paths
image_paths = list({p for pair in pairs for p in pair[:2]})

# Compute embeddings
start = time.time()
facenet_embeddings = compute_facenet_embeddings(image_paths)
insight_embeddings = compute_insight_embeddings(image_paths)
print(f"â±ï¸ Total embedding time: {time.time() - start:.2f} seconds")

def evaluate_model(pairs, embedding_dict, threshold):
    y_true, y_pred = [], []
    for img1, img2, label in pairs:
        if img1 in embedding_dict and img2 in embedding_dict:
            emb1, emb2 = embedding_dict[img1], embedding_dict[img2]
            sim = cosine_similarity([emb1], [emb2])[0][0]
            pred = 1 if sim > threshold else 0
            y_true.append(label)
            y_pred.append(pred)
    return y_true, y_pred

# Evaluate both models
y_true_facenet, y_pred_facenet = evaluate_model(pairs, facenet_embeddings, threshold=0.3)
y_true_insight, y_pred_insight = evaluate_model(pairs, insight_embeddings, threshold=0.35)

def print_metrics(name, y_true, y_pred):
    acc = accuracy_score(y_true, y_pred)
    prec = precision_score(y_true, y_pred, zero_division=0)
    rec = recall_score(y_true, y_pred, zero_division=0)
    f1 = f1_score(y_true, y_pred, zero_division=0)
    cm = confusion_matrix(y_true, y_pred)

    print(f"\nðŸ“Œ {name} Results")
    print(f"Accuracy : {acc:.4f}")
    print(f"Precision: {prec:.4f}")
    print(f"Recall   : {rec:.4f}")
    print(f"F1 Score : {f1:.4f}")
    print(f"Confusion Matrix:\n{cm}")

    return {"Model": name, "Accuracy": acc, "Precision": prec, "Recall": rec, "F1": f1, "CM": cm}

results = []
results.append(print_metrics("FaceNet512", y_true_facenet, y_pred_facenet))
results.append(print_metrics("InsightFace_ViT", y_true_insight, y_pred_insight))

def plot_confusion_matrix(cm, title):
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Diff', 'Same'], yticklabels=['Diff', 'Same'])
    plt.title(title)
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.show()

plot_confusion_matrix(results[0]['CM'], "FaceNet512 Confusion Matrix")
plot_confusion_matrix(results[1]['CM'], "InsightFace ViT Confusion Matrix")

def evaluate_model(pairs, embedding_dict, threshold):
    y_true, y_pred = [], []
    for img1, img2, label in pairs:
        if img1 in embedding_dict and img2 in embedding_dict:
            emb1, emb2 = embedding_dict[img1], embedding_dict[img2]
            sim = cosine_similarity([emb1], [emb2])[0][0]
            pred = 1 if sim > threshold else 0
            y_true.append(label)
            y_pred.append(pred)
    return y_true, y_pred

# Evaluate both models
y_true_facenet, y_pred_facenet = evaluate_model(pairs, facenet_embeddings, threshold=0.5)
y_true_insight, y_pred_insight = evaluate_model(pairs, insight_embeddings, threshold=0.35)

def print_metrics(name, y_true, y_pred):
    acc = accuracy_score(y_true, y_pred)
    prec = precision_score(y_true, y_pred, zero_division=0)
    rec = recall_score(y_true, y_pred, zero_division=0)
    f1 = f1_score(y_true, y_pred, zero_division=0)
    cm = confusion_matrix(y_true, y_pred)

    print(f"\nðŸ“Œ {name} Results")
    print(f"Accuracy : {acc:.4f}")
    print(f"Precision: {prec:.4f}")
    print(f"Recall   : {rec:.4f}")
    print(f"F1 Score : {f1:.4f}")
    print(f"Confusion Matrix:\n{cm}")

    return {"Model": name, "Accuracy": acc, "Precision": prec, "Recall": rec, "F1": f1, "CM": cm}

results = []
results.append(print_metrics("FaceNet512", y_true_facenet, y_pred_facenet))
results.append(print_metrics("InsightFace_ViT", y_true_insight, y_pred_insight))

def plot_confusion_matrix(cm, title):
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Diff', 'Same'], yticklabels=['Diff', 'Same'])
    plt.title(title)
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.show()

plot_confusion_matrix(results[0]['CM'], "FaceNet512 Confusion Matrix")
plot_confusion_matrix(results[1]['CM'], "InsightFace ViT Confusion Matrix")